# ðŸ§  Reinforcement Learning Algorithms

![GitHub Repo stars](https://img.shields.io/github/stars/MainakVerse/Reinforcement-Learning?style=for-the-badge&color=yellow)
![GitHub forks](https://img.shields.io/github/forks/MainakVerse/Reinforcement-Learning?style=for-the-badge&color=orange)
![GitHub issues](https://img.shields.io/github/issues/MainakVerse/Reinforcement-Learning?style=for-the-badge&color=blue)
![GitHub pull requests](https://img.shields.io/github/issues-pr/MainakVerse/Reinforcement-Learning?style=for-the-badge&color=brightgreen)
![License](https://img.shields.io/github/license/MainakVerse/Reinforcement-Learning?style=for-the-badge&color=red)
![Made with Python](https://img.shields.io/badge/Made%20with-Python-blue.svg?style=for-the-badge)
![Contributions welcome](https://img.shields.io/badge/Contributions-Welcome-brightgreen.svg?style=for-the-badge)

---

## ðŸ“˜ Overview

This repository contains **27 Reinforcement Learning (RL) algorithms**, built **from scratch in Python**, arranged in logical order for clarity â€” from classical Q-learning to modern deep and evolutionary approaches.  
Each algorithm will have:
- A clean, commented function-only implementation  
- Example environments (Gym / custom)
- Reference equations and learning flow diagrams

---

## ðŸ§© List of Reinforcement Learning Algorithms

| No. | Algorithm Name | Category |
|:---:|:----------------|:----------|
| **1** | Q-Learning | Value-Based |
| **2** | Deep Q-Network (DQN) | Value-Based |
| **3** | Double DQN (DDQN) | Value-Based |
| **4** | Dueling DQN | Value-Based |
| **5** | Prioritized Experience Replay DQN | Value-Based |
| **6** | SARSA (State-Action-Reward-State-Action) | Value-Based |
| **7** | Expected SARSA | Value-Based |
| **8** | REINFORCE (Monte Carlo Policy Gradient) | Policy-Based |
| **9** | Actor-Critic | Policy-Based |
| **10** | Advantage Actor-Critic (A2C) | Policy-Based |
| **11** | Asynchronous Advantage Actor-Critic (A3C) | Policy-Based |
| **12** | Trust Region Policy Optimization (TRPO) | Policy-Based |
| **13** | Proximal Policy Optimization (PPO) | Policy-Based |
| **14** | Deep Deterministic Policy Gradient (DDPG) | Actorâ€“Critic |
| **15** | Twin Delayed DDPG (TD3) | Actorâ€“Critic |
| **16** | Soft Actor-Critic (SAC) | Actorâ€“Critic |
| **17** | Stochastic Value Gradients (SVG) | Actorâ€“Critic |
| **18** | Deterministic Policy Gradient (DPG) | Actorâ€“Critic |
| **19** | Dyna-Q | Model-Based |
| **20** | Model-Based Policy Optimization (MBPO) | Model-Based |
| **21** | PlaNet (Planning Network) | Model-Based |
| **22** | Dreamer / DreamerV2 | Model-Based |
| **23** | PETS (Probabilistic Ensembles with Trajectory Sampling) | Model-Based |
| **24** | Cross-Entropy Method (CEM) | Evolutionary |
| **25** | Genetic Algorithms (GA) for RL | Evolutionary |
| **26** | NeuroEvolution of Augmenting Topologies (NEAT) | Evolutionary |
| **27** | Covariance Matrix Adaptation Evolution Strategy (CMA-ES) | Evolutionary |

---


